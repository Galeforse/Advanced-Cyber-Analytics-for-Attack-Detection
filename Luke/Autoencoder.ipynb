{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4503cb4c-02e9-46ec-b99e-c0e6b6e758a7",
   "metadata": {},
   "source": [
    "# Convo AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87d9ddbe-1fa5-480e-98c9-09d94c254cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import keras\n",
    "from keras import layers, models\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a8e019d-8586-49ca-aa2f-f8e25bcdb177",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukehawley/opt/anaconda3/envs/pyCP_APR/lib/python3.8/site-packages/numpy/lib/arraysetops.py:583: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  # Otherwise use sorting\n"
     ]
    }
   ],
   "source": [
    "authentication_data = pd.read_csv('https://github.com/Galeforse/Advanced-Cyber-Analytics-for-Attack-Detection/raw/main/Data/Authentication%20data.gz', compression='gzip', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "214619ff-4f92-4fea-9b24-3cdfd7c86b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_usernames = list(pd.read_csv('https://github.com/Galeforse/Advanced-Cyber-Analytics-for-Attack-Detection/raw/main/Data/AuthUserNames.txt', header=None)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc23243a-d513-4286-b616-78b80162adef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splits a dataframe into n chunks\n",
    "def split_dataframe(df,n): \n",
    "    chunks = list()\n",
    "    chunk_size = int(np.round(df.shape[0]/n))\n",
    "    num_chunks = n\n",
    "    for i in range(num_chunks):\n",
    "        if i != num_chunks-1:\n",
    "            chunks.append(df[i*chunk_size:(i+1)*chunk_size])\n",
    "        else:\n",
    "            chunks.append(df[i*chunk_size:])\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6abc2c0f-dd5c-4d96-aea0-408251886ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "auth_index_list = authentication_data.index.tolist()\n",
    "auth_start_days = [i for i, e in enumerate(auth_index_list) if e == 0]\n",
    "auth_start_days.append(len(authentication_data))\n",
    "\n",
    "def auth_type_un_df(user,n):\n",
    "    auth_type_df = pd.DataFrame(index = list(authentication_data['Authent Type'].unique()))\n",
    "    n = n\n",
    "\n",
    "    for i in range(len(auth_start_days)-1):\n",
    "        chunks = split_dataframe(authentication_data[auth_start_days[i]:auth_start_days[i+1]],n)\n",
    "        for j in range(n):\n",
    "                data = chunks[j]\n",
    "                auth_type_data = data[data['UserName'] == user].groupby('Authent Type').size()\n",
    "                auth_type_df[i*n + j] = auth_type_df.index.to_series().map(auth_type_data.to_dict())\n",
    "\n",
    "    auth_type_df = auth_type_df.transpose()\n",
    "    auth_type_df = auth_type_df.fillna(0)\n",
    "    \n",
    "    return auth_type_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c649633c-32ce-42dc-8239-8a21929ad892",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = auth_type_un_df(rt_usernames[0],24)\n",
    "rank_2 =  np.array(df)\n",
    "rank_3 = tf.stack([rank_2[i:i+23] for i in np.arange(0,len(rank_2)-1,24)])\n",
    "\n",
    "npad = ((0, 0), (1, 0), (1, 0))    \n",
    "rank_3 = np.pad(rank_3, pad_width=npad, mode='constant', constant_values=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d5680651-25ad-4556-812e-a2d0f7f63f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, Cropping2D\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "input_img = Input(shape=(24, 14, 1)) \n",
    "\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "#x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "#x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "#x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "#x = Conv2D(32, (3, 3), activation='relu', padding='same')(encoded)\n",
    "#x = UpSampling2D((2, 2))(x)\n",
    "#x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "#x = UpSampling2D((2, 2))(x)\n",
    "#x = Conv2D(32, (3, 3), activation='relu')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "convo_autoencoder = Model(input_img, decoded)\n",
    "convo_autoencoder.compile(metrics=['accuracy'], optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5eec1c6a-1a9e-4a45-80a4-88f3e2c94343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 1s 683ms/step - loss: 0.2572 - accuracy: 0.7162\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.2550 - accuracy: 0.7435\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2530 - accuracy: 0.7792\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.2508 - accuracy: 0.8272\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.2487 - accuracy: 0.8664\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2466 - accuracy: 0.9019\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2444 - accuracy: 0.9220\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2423 - accuracy: 0.9383\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.2402 - accuracy: 0.9530\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.2380 - accuracy: 0.9629\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f814808ee20>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo_autoencoder.fit(rank_3[:57], rank_3[:57], epochs=10, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8c60161d-1dca-47cc-a9e5-4d6ee5efbe9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_11 (InputLayer)        [(None, 24, 14, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_49 (Conv2D)           (None, 24, 14, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 12, 7, 32)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_21 (UpSampling (None, 24, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_50 (Conv2D)           (None, 24, 14, 1)         289       \n",
      "=================================================================\n",
      "Total params: 609\n",
      "Trainable params: 609\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "convo_autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c43aa530-d5fe-42a7-900f-40b48802741e",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruction = convo_autoencoder.predict(np.array(rank_3[79]).reshape(1,24,14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9f2191b8-864d-4e8b-a13e-a6be0862e052",
   "metadata": {},
   "outputs": [],
   "source": [
    "convo_error_list = []\n",
    "for i in range (33):\n",
    "    convo_reconstruction = convo_autoencoder.predict(np.array(rank_3[57+i]).reshape(1,24,14))\n",
    "    convo_reconstruction = convo_reconstruction.reshape(1, 24, 14)\n",
    "    convo_error = np.mean(np.power(np.array(rank_3[57+i]).reshape(1,24,14)-convo_reconstruction, 2))\n",
    "    convo_error_list.append(convo_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c85666c6-8ed0-4eec-9eef-0cdbc04e4cc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'whiskers': [<matplotlib.lines.Line2D at 0x7f81474ea430>,\n",
       "  <matplotlib.lines.Line2D at 0x7f81474eafd0>],\n",
       " 'caps': [<matplotlib.lines.Line2D at 0x7f8148250730>,\n",
       "  <matplotlib.lines.Line2D at 0x7f81482501c0>],\n",
       " 'boxes': [<matplotlib.lines.Line2D at 0x7f81471addc0>],\n",
       " 'medians': [<matplotlib.lines.Line2D at 0x7f8148250c40>],\n",
       " 'fliers': [<matplotlib.lines.Line2D at 0x7f81477a9970>],\n",
       " 'means': []}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.boxplot(convo_error_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407ddc9f-ca0e-4b3a-a423-7a5b6bef1410",
   "metadata": {},
   "source": [
    "# Regular AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7f7417be-a347-4cf5-9b15-21ddbf005361",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = Input(shape=(24, 14, 1)) \n",
    "\n",
    "encoded = layers.Dense(32, activation='relu')(input_img)\n",
    "encoded = layers.Dense(16, activation='relu')(encoded)\n",
    "encoded = layers.Dense(8, activation='relu')(encoded)\n",
    "\n",
    "decoded = layers.Dense(16, activation='relu')(encoded)\n",
    "decoded = layers.Dense(32, activation='relu')(decoded)\n",
    "decoded = layers.Dense(32, activation='softmax')(decoded)\n",
    "\n",
    "autoencoder = keras.Model(input_img, decoded)\n",
    "autoencoder.compile(metrics=['accuracy'], optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "869c34b0-0ef5-4b23-ba61-0be20b55a160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /Users/lukehawley/opt/anaconda3/envs/pyCP_APR/lib/python3.8/site-packages/keras/engine/training.py:830 train_function  *\n        return step_function(self, iterator)\n    /Users/lukehawley/opt/anaconda3/envs/pyCP_APR/lib/python3.8/site-packages/keras/engine/training.py:813 run_step  *\n        outputs = model.train_step(data)\n    /Users/lukehawley/opt/anaconda3/envs/pyCP_APR/lib/python3.8/site-packages/keras/engine/training.py:771 train_step  *\n        loss = self.compiled_loss(\n    /Users/lukehawley/opt/anaconda3/envs/pyCP_APR/lib/python3.8/site-packages/keras/engine/compile_utils.py:201 __call__  *\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    /Users/lukehawley/opt/anaconda3/envs/pyCP_APR/lib/python3.8/site-packages/keras/losses.py:142 __call__  *\n        losses = call_fn(y_true, y_pred)\n    /Users/lukehawley/opt/anaconda3/envs/pyCP_APR/lib/python3.8/site-packages/keras/losses.py:246 call  *\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    /Users/lukehawley/opt/anaconda3/envs/pyCP_APR/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:206 wrapper  **\n        return target(*args, **kwargs)\n    /Users/lukehawley/opt/anaconda3/envs/pyCP_APR/lib/python3.8/site-packages/keras/losses.py:1202 mean_squared_error\n        return backend.mean(tf.math.squared_difference(y_pred, y_true), axis=-1)\n    /Users/lukehawley/opt/anaconda3/envs/pyCP_APR/lib/python3.8/site-packages/tensorflow/python/ops/gen_math_ops.py:10422 squared_difference\n        _, _, _op, _outputs = _op_def_library._apply_op_helper(\n    /Users/lukehawley/opt/anaconda3/envs/pyCP_APR/lib/python3.8/site-packages/tensorflow/python/framework/op_def_library.py:748 _apply_op_helper\n        op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n    /Users/lukehawley/opt/anaconda3/envs/pyCP_APR/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:599 _create_op_internal\n        return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n    /Users/lukehawley/opt/anaconda3/envs/pyCP_APR/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:3557 _create_op_internal\n        ret = Operation(\n    /Users/lukehawley/opt/anaconda3/envs/pyCP_APR/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:2041 __init__\n        self._c_op = _create_c_op(self._graph, node_def, inputs,\n    /Users/lukehawley/opt/anaconda3/envs/pyCP_APR/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:1883 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Dimensions must be equal, but are 14 and 24 for '{{node mean_squared_error/SquaredDifference}} = SquaredDifference[T=DT_FLOAT](model_16/dense_29/Softmax, IteratorGetNext:1)' with input shapes: [?,24,14,32], [?,24,14].\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-89-337d07e97b4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrank_3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m57\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank_3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m57\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/pyCP_APR/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1156\u001b[0m                 _r=1):\n\u001b[1;32m   1157\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1158\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1159\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/pyCP_APR/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/pyCP_APR/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/pyCP_APR/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    761\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m--> 763\u001b[0;31m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    764\u001b[0m             *args, **kwds))\n\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/pyCP_APR/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3048\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3049\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3050\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3051\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/pyCP_APR/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3443\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3444\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3445\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/pyCP_APR/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3277\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3278\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3279\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3280\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3281\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/pyCP_APR/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    997\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 999\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/pyCP_APR/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/pyCP_APR/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    984\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /Users/lukehawley/opt/anaconda3/envs/pyCP_APR/lib/python3.8/site-packages/keras/engine/training.py:830 train_function  *\n        return step_function(self, iterator)\n    /Users/lukehawley/opt/anaconda3/envs/pyCP_APR/lib/python3.8/site-packages/keras/engine/training.py:813 run_step  *\n        outputs = model.train_step(data)\n    /Users/lukehawley/opt/anaconda3/envs/pyCP_APR/lib/python3.8/site-packages/keras/engine/training.py:771 train_step  *\n        loss = self.compiled_loss(\n    /Users/lukehawley/opt/anaconda3/envs/pyCP_APR/lib/python3.8/site-packages/keras/engine/compile_utils.py:201 __call__  *\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    /Users/lukehawley/opt/anaconda3/envs/pyCP_APR/lib/python3.8/site-packages/keras/losses.py:142 __call__  *\n        losses = call_fn(y_true, y_pred)\n    /Users/lukehawley/opt/anaconda3/envs/pyCP_APR/lib/python3.8/site-packages/keras/losses.py:246 call  *\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    /Users/lukehawley/opt/anaconda3/envs/pyCP_APR/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:206 wrapper  **\n        return target(*args, **kwargs)\n    /Users/lukehawley/opt/anaconda3/envs/pyCP_APR/lib/python3.8/site-packages/keras/losses.py:1202 mean_squared_error\n        return backend.mean(tf.math.squared_difference(y_pred, y_true), axis=-1)\n    /Users/lukehawley/opt/anaconda3/envs/pyCP_APR/lib/python3.8/site-packages/tensorflow/python/ops/gen_math_ops.py:10422 squared_difference\n        _, _, _op, _outputs = _op_def_library._apply_op_helper(\n    /Users/lukehawley/opt/anaconda3/envs/pyCP_APR/lib/python3.8/site-packages/tensorflow/python/framework/op_def_library.py:748 _apply_op_helper\n        op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n    /Users/lukehawley/opt/anaconda3/envs/pyCP_APR/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:599 _create_op_internal\n        return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n    /Users/lukehawley/opt/anaconda3/envs/pyCP_APR/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:3557 _create_op_internal\n        ret = Operation(\n    /Users/lukehawley/opt/anaconda3/envs/pyCP_APR/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:2041 __init__\n        self._c_op = _create_c_op(self._graph, node_def, inputs,\n    /Users/lukehawley/opt/anaconda3/envs/pyCP_APR/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:1883 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Dimensions must be equal, but are 14 and 24 for '{{node mean_squared_error/SquaredDifference}} = SquaredDifference[T=DT_FLOAT](model_16/dense_29/Softmax, IteratorGetNext:1)' with input shapes: [?,24,14,32], [?,24,14].\n"
     ]
    }
   ],
   "source": [
    "autoencoder.fit(rank_3[:57], rank_3[:57], epochs=10, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72daed54-0e4e-436d-8557-eb545df1980e",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_list = []\n",
    "for i in range (33):\n",
    "    reconstruction = autoencoder.predict(np.array(rank_3[57+i]).reshape(1,24,14))\n",
    "    reconstruction = reconstruction.reshape(1, 24, 14)\n",
    "    error = np.mean(np.power(np.array(rank_3[57+i]).reshape(1,24,14)-reconstruction, 2))\n",
    "    error_list.append(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e37be03-9a54-49b7-84d8-3cc12d5389a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(error_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
