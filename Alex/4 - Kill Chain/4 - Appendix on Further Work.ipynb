{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c033013",
   "metadata": {},
   "source": [
    "### Further work towards improving our KC implementation results\n",
    "\n",
    "_Note: This paper is a short appendix for the [main paper on KC implementation, found here](https://github.com/Galeforse/Advanced-Cyber-Analytics-for-Attack-Detection/blob/main/Alex/4%20-%20Kill%20Chain/3%20-%20KC%20implementation.ipynb). Follow the link to better understand its purpose._\n",
    "\n",
    "The purpose of this paper is to offer some insight into ways of improving our results obtained when performing Kill-Chain stages classification using a Decision Tree model. We will _not_ focus on data engineering aspects, such as complexity optimization or code smoothing, but rather explore avenues for improving our methods that lead to the final results. In particular, the choice of decision tree has already been explained in the former work. \n",
    "\n",
    "This appendix will exclusively tackle two main points of contestation regarding our method: \n",
    "\n",
    "- 1. How could we improve our **StageIntegrity()** function to be most suitable for our desired outcome\n",
    "\n",
    "\n",
    "- 2. How could **points assignment** be controlled given the decisions derived from the tree?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe368673",
   "metadata": {},
   "source": [
    "### 1. StageIntegrity() function\n",
    "\n",
    "The algorithm itself has been explained in the main paper. There, we achieved results of ~ 34.4% 'integrity', which we claimed to be satisfied with. However, we haven't properly explained why that is the case. Clearly, significantly smaller values for integrity such as in the realm of 5% - 15% would imply that a huge portion of our stages have gaps between the Maximum points assigned and the Minimum on a single connection larger than 10% of the Sum of all events, by definition. This, in turn, would make the chronology redistribution function little to no effective, provided it considers the redistribution factor in terms of the value of Sum/10. Fewer connections being redistributed consequently leads to less chronology updating of the results and overall poorer assignment.\n",
    "\n",
    "It then seems intuitive that the other end of the spectrum, where we aim to achieve as close to 100% 'integrity' as possible is the right choice. We argue that is not the case either. Indeed, a result of 100% would mean that stages are scored close enough to each other so that the chronology redistribution will be able to correct all of them. However, this correction would hinder more than it would help in the sequence of events. With virtually _all_ scores being close together, there is little ground to distinguish stages within our decision making process, since the seemingly trivial, individual choice of assigning +0.25 or +0.5 to a stage would be decisive not only for a connection, but for a potentially very long sequence of connections afterwards. With the current decision tree system, we aim for a portion of the connections to hold 'threshold scores', where deciding between StageN-1, StageN or StageN+1 is a difficult task and a matter of very few points - such values being represented through K-means as the boundaries between clusters. Nonetheless, by definition, not all connections should be as such, since clear decisions on assigning StageN should be available in a lot of instances, which would be where cluster do not overlap. On account of these observations, our team was pleased with the percentages obtained on our data.\n",
    "\n",
    "The question that remains open to further exploration is \"what is the precise value sought to be obtained from the test?\". As mentioned, we hope to have obtained one of the better outcomes for this purpose, but we cannot know for sure apart from the previous observations. The main intuition is to trial and error different intervals of percentages and see what results are obtained from them at the end. Within our work, we have tried values for the StageIntegrity() test such as ~11%, ~32%, ~55% and lastly ~34%. This empirical approach led us to believe that whatever the most suitable interval is, it must lie between 30 and 45% - since the 11% and 55% experiments respectively provided us with the worst results out of the collection, for very different reasons. The former provided almost no chronology update, as expected, whereas the latter shifted the balance too much in favour of reconnaissance - even worse than the initial results would otherwise output. In conclusion, more empirical testing of different percentages obtained from various mathematical combinations of the points assigned is sure to lead to improved end-results, and remains the subject of further work to be done towards our model's optimal implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b44a851",
   "metadata": {},
   "source": [
    "### 2. Points assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28fc834",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**References**\n",
    "\n",
    "[1. Main KC implementation paper](https://github.com/Galeforse/Advanced-Cyber-Analytics-for-Attack-Detection/blob/main/Alex/4%20-%20Kill%20Chain/3%20-%20KC%20implementation.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
