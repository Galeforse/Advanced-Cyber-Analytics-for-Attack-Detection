{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need these libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install.packages(\"caret\")\n",
    "# install.packages(\"BBmisc\")\n",
    "# install.packages(\"data.table\")\n",
    "\n",
    "library(caret)\n",
    "library(BBmisc)\n",
    "library(data.table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use the iris dataset for exemplifying:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>Sepal.Length</th><th scope=col>Sepal.Width</th><th scope=col>Petal.Length</th><th scope=col>Petal.Width</th><th scope=col>Species</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>5.1   </td><td>3.5   </td><td>1.4   </td><td>0.2   </td><td>setosa</td></tr>\n",
       "\t<tr><td>4.9   </td><td>3.0   </td><td>1.4   </td><td>0.2   </td><td>setosa</td></tr>\n",
       "\t<tr><td>4.7   </td><td>3.2   </td><td>1.3   </td><td>0.2   </td><td>setosa</td></tr>\n",
       "\t<tr><td>4.6   </td><td>3.1   </td><td>1.5   </td><td>0.2   </td><td>setosa</td></tr>\n",
       "\t<tr><td>5.0   </td><td>3.6   </td><td>1.4   </td><td>0.2   </td><td>setosa</td></tr>\n",
       "\t<tr><td>5.4   </td><td>3.9   </td><td>1.7   </td><td>0.4   </td><td>setosa</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllll}\n",
       " Sepal.Length & Sepal.Width & Petal.Length & Petal.Width & Species\\\\\n",
       "\\hline\n",
       "\t 5.1    & 3.5    & 1.4    & 0.2    & setosa\\\\\n",
       "\t 4.9    & 3.0    & 1.4    & 0.2    & setosa\\\\\n",
       "\t 4.7    & 3.2    & 1.3    & 0.2    & setosa\\\\\n",
       "\t 4.6    & 3.1    & 1.5    & 0.2    & setosa\\\\\n",
       "\t 5.0    & 3.6    & 1.4    & 0.2    & setosa\\\\\n",
       "\t 5.4    & 3.9    & 1.7    & 0.4    & setosa\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| Sepal.Length | Sepal.Width | Petal.Length | Petal.Width | Species |\n",
       "|---|---|---|---|---|\n",
       "| 5.1    | 3.5    | 1.4    | 0.2    | setosa |\n",
       "| 4.9    | 3.0    | 1.4    | 0.2    | setosa |\n",
       "| 4.7    | 3.2    | 1.3    | 0.2    | setosa |\n",
       "| 4.6    | 3.1    | 1.5    | 0.2    | setosa |\n",
       "| 5.0    | 3.6    | 1.4    | 0.2    | setosa |\n",
       "| 5.4    | 3.9    | 1.7    | 0.4    | setosa |\n",
       "\n"
      ],
      "text/plain": [
       "  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n",
       "1 5.1          3.5         1.4          0.2         setosa \n",
       "2 4.9          3.0         1.4          0.2         setosa \n",
       "3 4.7          3.2         1.3          0.2         setosa \n",
       "4 4.6          3.1         1.5          0.2         setosa \n",
       "5 5.0          3.6         1.4          0.2         setosa \n",
       "6 5.4          3.9         1.7          0.4         setosa "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>150</li>\n",
       "\t<li>5</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 150\n",
       "\\item 5\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 150\n",
       "2. 5\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 150   5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "  Sepal.Length    Sepal.Width     Petal.Length    Petal.Width   \n",
       " Min.   :4.300   Min.   :2.000   Min.   :1.000   Min.   :0.100  \n",
       " 1st Qu.:5.100   1st Qu.:2.800   1st Qu.:1.600   1st Qu.:0.300  \n",
       " Median :5.800   Median :3.000   Median :4.350   Median :1.300  \n",
       " Mean   :5.843   Mean   :3.057   Mean   :3.758   Mean   :1.199  \n",
       " 3rd Qu.:6.400   3rd Qu.:3.300   3rd Qu.:5.100   3rd Qu.:1.800  \n",
       " Max.   :7.900   Max.   :4.400   Max.   :6.900   Max.   :2.500  \n",
       "       Species  \n",
       " setosa    :50  \n",
       " versicolor:50  \n",
       " virginica :50  \n",
       "                \n",
       "                \n",
       "                "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data(iris)\n",
    "head(iris)\n",
    "dim(iris)\n",
    "summary(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in summary.lm(fit):\n",
      "\"essentially perfect fit: summary may be unreliable\""
     ]
    },
    {
     "data": {
      "text/html": [
       "8.44777661718744e-31"
      ],
      "text/latex": [
       "8.44777661718744e-31"
      ],
      "text/markdown": [
       "8.44777661718744e-31"
      ],
      "text/plain": [
       "[1] 8.447777e-31"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Method 1 for MSE \n",
    "k<- 10\n",
    "train<- sample(1:nrow(iris), size=nrow(iris)*(k-1)/k, replace=FALSE)\n",
    "\tdf_train <- iris[train, ]\n",
    "\tdf_test <- iris[-train, ]\n",
    "\tfit <- lm(df_train[,1]~., data=df_train)\n",
    "\n",
    "fit_summ <- summary(fit)\n",
    "mean(fit_summ$residuals^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>pred</th><th scope=col>actual</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>8</th><td>5.0</td><td>5.0</td></tr>\n",
       "\t<tr><th scope=row>42</th><td>4.5</td><td>4.5</td></tr>\n",
       "\t<tr><th scope=row>68</th><td>5.8</td><td>5.8</td></tr>\n",
       "\t<tr><th scope=row>19</th><td>5.7</td><td>5.7</td></tr>\n",
       "\t<tr><th scope=row>115</th><td>5.8</td><td>5.8</td></tr>\n",
       "\t<tr><th scope=row>69</th><td>6.2</td><td>6.2</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ll}\n",
       "  & pred & actual\\\\\n",
       "\\hline\n",
       "\t8 & 5.0 & 5.0\\\\\n",
       "\t42 & 4.5 & 4.5\\\\\n",
       "\t68 & 5.8 & 5.8\\\\\n",
       "\t19 & 5.7 & 5.7\\\\\n",
       "\t115 & 5.8 & 5.8\\\\\n",
       "\t69 & 6.2 & 6.2\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| <!--/--> | pred | actual |\n",
       "|---|---|---|\n",
       "| 8 | 5.0 | 5.0 |\n",
       "| 42 | 4.5 | 4.5 |\n",
       "| 68 | 5.8 | 5.8 |\n",
       "| 19 | 5.7 | 5.7 |\n",
       "| 115 | 5.8 | 5.8 |\n",
       "| 69 | 6.2 | 6.2 |\n",
       "\n"
      ],
      "text/plain": [
       "    pred actual\n",
       "8   5.0  5.0   \n",
       "42  4.5  4.5   \n",
       "68  5.8  5.8   \n",
       "19  5.7  5.7   \n",
       "115 5.8  5.8   \n",
       "69  6.2  6.2   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "1.70627692092248e-30"
      ],
      "text/latex": [
       "1.70627692092248e-30"
      ],
      "text/markdown": [
       "1.70627692092248e-30"
      ],
      "text/plain": [
       "[1] 1.706277e-30"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Method 2 for MSE\n",
    "data <- data.frame(pred=predict(fit), actual= df_train[,1])\n",
    "head(data)\n",
    "mean((data$actual - data$pred)^2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second method is generally more reliable. I'm not entirely sure why. We'll use that any way.\n",
    "\n",
    "We'll initialize the MSE computation on the first feature of the iris dataset -- this is essentially what we need to really do for CV! We'll explore it on the other features afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "k<- 10\n",
    "m <- vector(length=k-1)\n",
    "\n",
    "while(k>1) {\n",
    "\ttrain<- sample(1:nrow(iris), size=nrow(iris)*(k-1)/k, replace=FALSE)\n",
    "\tdf_train <- iris[train, ]\n",
    "\tdf_test <- iris[-train, ]\n",
    "\tiris <- iris[train, ]\n",
    "\tk <- k-1\n",
    "\tfit <- lm(df_train[,1]~., data=df_train)\n",
    "\tdata <- data.frame(pred=predict(fit), actual= df_train[,1])\n",
    "\tm[k] <- mean((data$actual - data$pred)^2)\n",
    "\t}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "3.92765543351397e-31"
      ],
      "text/latex": [
       "3.92765543351397e-31"
      ],
      "text/markdown": [
       "3.92765543351397e-31"
      ],
      "text/plain": [
       "[1] 3.927655e-31"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss <- mean(m)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extend it to **all features** instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(warn=-1)\n",
    "K<- 10\n",
    "k<- 10\n",
    "m <- vector(length=(k-1)*ncol(iris))\n",
    "j<- 1\n",
    "\n",
    "for(i in 1:ncol(iris)) {\n",
    "\t# j<- j+ncol(iris)\n",
    "\tk<- 10\n",
    "\tdata(iris)\n",
    "\twhile(k>1) {\n",
    "\t\tset.seed(10)\n",
    "\t\ttrain<- sample(1:nrow(iris), size=nrow(iris)*(k-1)/k, replace=FALSE)\n",
    "\t\tdf_train <- iris[train, ]\n",
    "\t\tdf_test <- iris[-train, ]\n",
    "\t\tiris <- iris[train, ]\n",
    "\t\tk <- k-1\n",
    "\t\tfit <- lm(df_train[,i]~., data=df_train)\n",
    "\t\tdata <- data.frame(pred=predict(fit), actual= df_train[,1])\n",
    "\t\tm[j] <- mean((data$actual - data$pred)^2)\n",
    "\t\tj<- j+1\n",
    "\t\t}\n",
    "\t}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(warn=0) # The warnings come from the feature of iris which is characters\n",
    "                ## Obviously needs addressing on what we end up working on!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's chunk our results accordingly. At the moment, the resulting vector holds the losses throughout all datasets AND throghout all features. Fortunately, they're well ordered so we can separate them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_length <- K-1\n",
    "m1 <- split(m, ceiling(seq_along(m) / chunk_length))\n",
    "m1<- as.vector(m1)\n",
    "\n",
    "## Alternatively:\n",
    "\t# library(BBmisc)\n",
    "\t# chunked <- chunk(m, chunk.size=K-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 <- as.data.frame(m1)\n",
    "m1 <- transpose(transpose(m1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>V1</th><th scope=col>V2</th><th scope=col>V3</th><th scope=col>V4</th><th scope=col>V5</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>0.000000e+00</td><td>8.850593    </td><td>5.368370    </td><td>21.75356    </td><td>14.95570    </td></tr>\n",
       "\t<tr><td>1.932709e-30</td><td>8.687250    </td><td>5.534167    </td><td>21.80692    </td><td>14.86567    </td></tr>\n",
       "\t<tr><td>4.282388e-31</td><td>8.790190    </td><td>5.546095    </td><td>21.83667    </td><td>14.86790    </td></tr>\n",
       "\t<tr><td>7.538004e-31</td><td>8.789778    </td><td>5.780111    </td><td>22.20567    </td><td>15.24733    </td></tr>\n",
       "\t<tr><td>6.731613e-31</td><td>9.067467    </td><td>5.515733    </td><td>22.13520    </td><td>15.24520    </td></tr>\n",
       "\t<tr><td>2.235106e-31</td><td>9.496500    </td><td>5.184167    </td><td>22.16033    </td><td>15.27017    </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllll}\n",
       " V1 & V2 & V3 & V4 & V5\\\\\n",
       "\\hline\n",
       "\t 0.000000e+00 & 8.850593     & 5.368370     & 21.75356     & 14.95570    \\\\\n",
       "\t 1.932709e-30 & 8.687250     & 5.534167     & 21.80692     & 14.86567    \\\\\n",
       "\t 4.282388e-31 & 8.790190     & 5.546095     & 21.83667     & 14.86790    \\\\\n",
       "\t 7.538004e-31 & 8.789778     & 5.780111     & 22.20567     & 15.24733    \\\\\n",
       "\t 6.731613e-31 & 9.067467     & 5.515733     & 22.13520     & 15.24520    \\\\\n",
       "\t 2.235106e-31 & 9.496500     & 5.184167     & 22.16033     & 15.27017    \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| V1 | V2 | V3 | V4 | V5 |\n",
       "|---|---|---|---|---|\n",
       "| 0.000000e+00 | 8.850593     | 5.368370     | 21.75356     | 14.95570     |\n",
       "| 1.932709e-30 | 8.687250     | 5.534167     | 21.80692     | 14.86567     |\n",
       "| 4.282388e-31 | 8.790190     | 5.546095     | 21.83667     | 14.86790     |\n",
       "| 7.538004e-31 | 8.789778     | 5.780111     | 22.20567     | 15.24733     |\n",
       "| 6.731613e-31 | 9.067467     | 5.515733     | 22.13520     | 15.24520     |\n",
       "| 2.235106e-31 | 9.496500     | 5.184167     | 22.16033     | 15.27017     |\n",
       "\n"
      ],
      "text/plain": [
       "  V1           V2       V3       V4       V5      \n",
       "1 0.000000e+00 8.850593 5.368370 21.75356 14.95570\n",
       "2 1.932709e-30 8.687250 5.534167 21.80692 14.86567\n",
       "3 4.282388e-31 8.790190 5.546095 21.83667 14.86790\n",
       "4 7.538004e-31 8.789778 5.780111 22.20567 15.24733\n",
       "5 6.731613e-31 9.067467 5.515733 22.13520 15.24520\n",
       "6 2.235106e-31 9.496500 5.184167 22.16033 15.27017"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(m1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's all losses throughout all features and on all (9) testing partitions attempted. They're all sampled WITHOUT replacement, so we're certain to get a hold of the best out of them this way!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"The MSE of the fitted column 1 is 7.98266019364388e-31\"\n",
      "[1] \"The MSE of the fitted column 2 is 9.08334564961787\"\n",
      "[1] \"The MSE of the fitted column 3 is 5.38576284538507\"\n",
      "[1] \"The MSE of the fitted column 4 is 21.8025808641975\"\n",
      "[1] \"The MSE of the fitted column 5 is 14.9474416813639\"\n"
     ]
    }
   ],
   "source": [
    "loss <- vector(len=ncol(m1))\n",
    "for(i in 1:ncol(m1)){\n",
    "\tloss[i] <- mean(m1[, i])\n",
    "\t}\n",
    "\n",
    "for(i in 1:length(loss)) {\n",
    "\tprint(paste(\"The MSE of the fitted column\", i, \"is\", loss[i], sep=\" \"))\n",
    "\t}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iris was originally constructed to model the first column by all others, much like the 'cars' dataset and others. It's expected the first feature will fit so well (also why our first method of lm'ing gave a nearly perfect fit!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "10.2438262081129"
      ],
      "text/latex": [
       "10.2438262081129"
      ],
      "text/markdown": [
       "10.2438262081129"
      ],
      "text/plain": [
       "[1] 10.24383"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "overall_loss <- mean(loss, na.rm=TRUE)\n",
    "overall_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This provides a relevant measurement of how successful our CV was."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
