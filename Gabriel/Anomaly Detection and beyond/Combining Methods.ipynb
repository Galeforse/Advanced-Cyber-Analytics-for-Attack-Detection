{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e6e9bf8-3109-4389-92b7-4677befe362f",
   "metadata": {},
   "source": [
    "# Reducing the process and authentication data for easier usage\n",
    "\n",
    "In this notebook I am employing techniques I have researched, and also experimented with in the other notebooks found in this folder to reduce the dimensions of the Process and Authentication data for use with other methods.\n",
    "\n",
    "We start by importing various modules; check [here](https://github.com/Galeforse/Advanced-Cyber-Analytics-for-Attack-Detection/blob/main/Modules/01%20-%20Using%20Modules.ipynb) for information about using custom modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fae6767b-5c84-4189-a358-f8d5b140b997",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'G:/Users/Gabriel/Documents/Education/UoB/GitHubDesktop/Advanced-Cyber-Analytics-for-Attack-Detection/Modules/')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dt import *\n",
    "from startup_g import *\n",
    "import networkx as nx\n",
    "from pyvis.network import Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0377927f-b957-4b32-a29b-0cafc0618de6",
   "metadata": {},
   "source": [
    "I've imported a code block that does the import step for me to save line space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a5d2018-e35a-4638-8768-0c7a535de419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for local copy of Process data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\Programs\\Anaconda\\envs\\det\\lib\\site-packages\\numpy\\lib\\arraysetops.py:583: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process data fetched locally in 0:01:12.035862\n",
      "Looking for local copy of Auth data...\n",
      "Auth data fetched locally in 0:00:23.062016\n"
     ]
    }
   ],
   "source": [
    "df_p = process_import()\n",
    "df_a = auth_import()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af6b9b65-ea70-42cb-a0d6-e0ac03677775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserName</th>\n",
       "      <th>Device</th>\n",
       "      <th>ProcessName</th>\n",
       "      <th>ParentProcessName</th>\n",
       "      <th>DailyCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Comp748297$</td>\n",
       "      <td>Comp748297</td>\n",
       "      <td>Proc391839.exe</td>\n",
       "      <td>Proc387473</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Comp563664$</td>\n",
       "      <td>Comp563664</td>\n",
       "      <td>rundll32.exe</td>\n",
       "      <td>services</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>User607396</td>\n",
       "      <td>Comp609111</td>\n",
       "      <td>Proc417435.exe</td>\n",
       "      <td>Proc417435</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Comp641702$</td>\n",
       "      <td>Comp641702</td>\n",
       "      <td>Proc249569.exe</td>\n",
       "      <td>services</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Comp157389$</td>\n",
       "      <td>Comp157389</td>\n",
       "      <td>Proc402696.exe</td>\n",
       "      <td>services</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      UserName      Device     ProcessName ParentProcessName  DailyCount\n",
       "0  Comp748297$  Comp748297  Proc391839.exe        Proc387473           1\n",
       "1  Comp563664$  Comp563664    rundll32.exe          services           1\n",
       "2   User607396  Comp609111  Proc417435.exe        Proc417435           1\n",
       "3  Comp641702$  Comp641702  Proc249569.exe          services           1\n",
       "4  Comp157389$  Comp157389  Proc402696.exe          services           1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_list = df_p.index.tolist()\n",
    "proc_start_days = [i for i, e in enumerate(index_list) if e == 0]\n",
    "proc_start_days.append(len(df_p))\n",
    "df_p_d1 = df_p[proc_start_days[0]:proc_start_days[1]]\n",
    "df_p_d1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f548a06a-a9e8-43f5-a230-bc8095dc5a2b",
   "metadata": {},
   "source": [
    "In the above I indexed the data as done by Matt so that I could test the techniques below on a smaller subset of data for computational purposes. Though I have since deleted this testing, it's useful to leave in for potential future experimentation purposes.\n",
    "\n",
    "The function below was originally developed by me in another of my notebooks. It takes a dataset, counts the number of each different entry in a defined column of the dataset, then removes any with a count higher than `upper_value` or lower than `lower_value`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "910260e0-d24d-4f09-bc0d-c9378a00682f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_slicer(dataset,variable,upper_value,lower_value):\n",
    "    \"\"\"Cuts down data based on counts of entries\n",
    "    \n",
    "    Keyword arguments:\n",
    "    dataset -- pandas dataframe to cut down\n",
    "    variable -- name of column in string format to reduce by\n",
    "    upper_value -- any entry of the column with a count higher than this will be removed\n",
    "    lower_value -- any entry of the column with a count lower than this will be removed. set to 0 to not cut any from the lower end of the data.\n",
    "    \"\"\"\n",
    "    if dataset == \"p\":\n",
    "        z = df_p.groupby(variable).size().sort_values(ascending=False)\n",
    "        z = pd.DataFrame(z)\n",
    "        z.reset_index(level=0, inplace=True)\n",
    "        z.columns = [variable,'Count']\n",
    "        lims = z[z.Count < upper_value]\n",
    "        lims = lims[lims.Count > lower_value]\n",
    "        upper_lim = lims.head(1).index.values.astype(int)[0]\n",
    "        lower_lim = lims.tail(1).index.values.astype(int)[0]\n",
    "        y = z[(z[\"Count\"] <= z[\"Count\"][upper_lim]) & (z[\"Count\"] >= z[\"Count\"][lower_lim])]\n",
    "        x = z[z[\"Count\"] > z[\"Count\"][upper_lim]]\n",
    "        v = z[z[\"Count\"] < z[\"Count\"][lower_lim]]\n",
    "        counts_p_reduced = y\n",
    "        temp = []\n",
    "        temp.append(x)\n",
    "        temp.append(v)\n",
    "        counts_p_discard = pd.concat(temp,axis=0)\n",
    "        return counts_p_reduced, counts_p_discard\n",
    "    if dataset == \"a\":\n",
    "        z = df_a.groupby(variable).size().sort_values(ascending=False)\n",
    "        z = pd.DataFrame(z)\n",
    "        z.reset_index(level=0, inplace=True)\n",
    "        z.columns = [variable,'Count']\n",
    "        lims = z[z.Count < upper_value]\n",
    "        lims = lims[lims.Count > lower_value]\n",
    "        upper_lim = lims.head(1).index.values.astype(int)[0]\n",
    "        lower_lim = lims.tail(1).index.values.astype(int)[0]\n",
    "        y = z[(z[\"Count\"] <= z[\"Count\"][upper_lim]) & (z[\"Count\"] >= z[\"Count\"][lower_lim])]\n",
    "        x = z[z[\"Count\"] > z[\"Count\"][upper_lim]]\n",
    "        v = z[z[\"Count\"] < z[\"Count\"][lower_lim]]\n",
    "        counts_a_reduced = y\n",
    "        temp = []\n",
    "        temp.append(x)\n",
    "        temp.append(v)\n",
    "        counts_a_discard = pd.concat(temp,axis=0)\n",
    "        return counts_a_reduced, counts_a_discard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013c5279-de24-452e-b347-e50f92ef9357",
   "metadata": {},
   "source": [
    "The following block of code applies the `data_slicer` defined above to our our datasets. We have to run it twice, once for process and once for authentication. It runs on the variables defined in the script, with values being chosen by me based on the boxplots that I plotted in another notebook. The boxplots can be found [here for authentication](https://github.com/Galeforse/Advanced-Cyber-Analytics-for-Attack-Detection/tree/main/Gabriel/Plots/Boxplot/Auth) and [here for process](https://github.com/Galeforse/Advanced-Cyber-Analytics-for-Attack-Detection/tree/main/Gabriel/Plots/Boxplot/Process).\n",
    "\n",
    "It outputs the reduced data and when calling the function we assign this to a new cutdown variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03032647-b06b-4664-bf14-54e55ae73872",
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_data_reducer(dataset):\n",
    "    if dataset == \"p\":\n",
    "        counts_p_reduced_un, counts_p_discard_un = data_slicer(\"p\",\"UserName\",7600,0)\n",
    "        counts_p_reduced_d, counts_p_discard_d = data_slicer(\"p\",\"Device\",9500,0)\n",
    "        counts_p_discard_un = counts_p_discard_un[\"UserName\"].tolist()\n",
    "        counts_p_discard_d = counts_p_discard_d[\"Device\"].tolist()\n",
    "        print(\"Starting length of dataframe: \"+str(len(df_p)))\n",
    "        df_p_cut = df_p[~df_p[\"UserName\"].isin(counts_p_discard_un)]\n",
    "        print(\"1st drop length of dataframe: \"+str(len(df_p_cut)))\n",
    "        df_p_cut = df_p_cut[~df_p_cut[\"Device\"].isin(counts_p_discard_d)]\n",
    "        print(\"Final length of dataframe: \"+str(len(df_p_cut)))\n",
    "        return df_p_cut\n",
    "    elif dataset == \"a\":\n",
    "        counts_a_reduced_un, counts_a_discard_un = data_slicer(\"a\",\"UserName\",1600,0)\n",
    "        counts_a_reduced_sd, counts_a_discard_sd = data_slicer(\"a\",\"SrcDevice\",3300,0)\n",
    "        #counts_a_reduced_dd, counts_a_discard_dd = data_slicer(\"a\",\"DstDevice\",350,0)\n",
    "        counts_a_discard_un = counts_a_discard_un[\"UserName\"].tolist()\n",
    "        counts_a_discard_sd = counts_a_discard_sd[\"SrcDevice\"].tolist()\n",
    "        #counts_a_discard_dd = counts_a_discard_dd[\"DstDevice\"].tolist()\n",
    "        print(\"Starting length of dataframe: \"+str(len(df_a)))\n",
    "        df_a_cut = df_a[~df_a[\"UserName\"].isin(counts_a_discard_un)]\n",
    "        print(\"1st drop length of dataframe: \"+str(len(df_a_cut)))\n",
    "        df_a_cut = df_a_cut[~df_a_cut[\"SrcDevice\"].isin(counts_a_discard_sd)]\n",
    "        #print(\"2nd drop length of dataframe: \"+str(len(df_a_cut)))\n",
    "        #df_a_cut = df_a_cut[~df_a_cut[\"DstDevice\"].isin(counts_a_discard_dd)]\n",
    "        print(\"Final length of dataframe: \"+str(len(df_a_cut)))\n",
    "        return df_a_cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebccdd8b-7716-4433-bf25-87410b5f1350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting length of dataframe: 55981618\n",
      "1st drop length of dataframe: 55334015\n",
      "Final length of dataframe: 53171763\n",
      "Completed in :0:00:33.430418\n",
      "\n",
      "Starting length of dataframe: 15953681\n",
      "1st drop length of dataframe: 12940224\n",
      "Final length of dataframe: 11793285\n",
      "Completed in :0:00:10.142453\n"
     ]
    }
   ],
   "source": [
    "dtn()\n",
    "df_p_cut1 = total_data_reducer(\"p\")\n",
    "gen_end()\n",
    "print(\"\")\n",
    "dtn()\n",
    "df_a_cut1 = total_data_reducer(\"a\")\n",
    "gen_end()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62a486f-d2f7-4362-af3a-662ba11e05ce",
   "metadata": {},
   "source": [
    "The `data_reducer` function below does a similar thing to above however this time we are using network analysis to drop the small data. The reason we do not want to drop all data with a single or few connections is that it is quite possible that they could be attached to a larger cluster and could be relevant, therefore by dropping small compoments in the following block, we avoid losing these, only dropping small clusters of connections (which of course includes those with only appear once). After dropping these nodes, the source and destination nodes are listed in order to then reduce the data further to have only the unremoved points included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0076c2fd-3d30-4ea4-97d7-43215869794b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_reducer(df,sourc,targ,comp):\n",
    "    G = nx.from_pandas_edgelist(df,source=sourc,target=targ)\n",
    "    for component in list(nx.connected_components(G)):\n",
    "        if len(component)<comp:\n",
    "            for node in component:\n",
    "                G.remove_node(node)\n",
    "    source_edge = []\n",
    "    targ_edge = []\n",
    "    for e in G.edges():\n",
    "        source, target = e\n",
    "        source_edge.append(source)\n",
    "        targ_edge.append(target)\n",
    "    source_edge = list(dict.fromkeys(source_edge))\n",
    "    targ_edge = list(dict.fromkeys(targ_edge))\n",
    "    df_cut = df[df[sourc].isin(source_edge)]\n",
    "    df_cut = df_cut[df_cut[targ].isin(targ_edge)]\n",
    "    return df_cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a242d3e-a33e-4487-97dd-df25e82ece3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of process data before calling data_reducer: 53171763\n",
      "length of process data after calling data_reducer: 34298709\n",
      "Data reduced in size by 35.489999999999995 %.\n",
      "\n",
      "Completed in :0:02:45.020675\n"
     ]
    }
   ],
   "source": [
    "x = len(df_p_cut1)\n",
    "dtn()\n",
    "print(\"length of process data before calling data_reducer: \"+str(x))\n",
    "df_p_cut = data_reducer(df_p_cut1,\"UserName\",\"Device\",5)\n",
    "y = len(df_p_cut)\n",
    "print(\"length of process data after calling data_reducer: \"+str(y))\n",
    "print(\"Data reduced in size by \"+str(100 - round((y/x)*100,2))+\" %.\")\n",
    "print(\"\")\n",
    "gen_end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10cddb34-3658-4569-9a41-568d35c8021f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of auth data before calling data_reducer: 11793285\n",
      "length of auth data after calling data_reducer: 6927651\n",
      "Data reduced in size by 41.26 %.\n",
      "\n",
      "Completed in :0:00:40.158020\n"
     ]
    }
   ],
   "source": [
    "x = len(df_a_cut1)\n",
    "dtn()\n",
    "print(\"length of auth data before calling data_reducer: \"+str(x))\n",
    "df_a_cut = data_reducer(df_a_cut1,\"UserName\",\"SrcDevice\",5)\n",
    "y = len(df_a_cut)\n",
    "print(\"length of auth data after calling data_reducer: \"+str(y))\n",
    "print(\"Data reduced in size by \"+str(100 - round((y/x)*100,2))+\" %.\")\n",
    "print(\"\")\n",
    "gen_end()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b968a19b-0e60-427e-a805-44a787825efa",
   "metadata": {},
   "source": [
    "Total process reduction percentage after applying both methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e462ed6d-e453-4d5d-908a-5765975adde2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38.73"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100-round((len(df_p_cut)/len(df_p))*100,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1979ea7a-4142-473e-a089-c5b545d56ac9",
   "metadata": {},
   "source": [
    "Total authentication reduction percentage after applying both methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "accf99de-e936-4e16-a9a2-e7f64488d7aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56.58"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100-round((len(df_a_cut)/len(df_a))*100,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96470813-e64c-4861-9c0f-151e4948d023",
   "metadata": {},
   "source": [
    "We then save these reduced dataframes to `.csv.gz` files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "608bca3f-a6f1-4f23-a792-078bebe1c7bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_p_cut.to_csv(\"G:/Users/Gabriel/Documents/Education/UoB/GitHubDesktop/Advanced-Cyber-Analytics-for-Attack-Detection/Data/Reduced/proc_data_reduced.csv.gz\",compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8b5490-9c81-4bdc-b199-d3c77c71612c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_a_cut.to_csv(\"G:/Users/Gabriel/Documents/Education/UoB/GitHubDesktop/Advanced-Cyber-Analytics-for-Attack-Detection/Data/Reduced/auth_data_reduced.csv.gz\",compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0550d10-2e12-464e-b665-dfcb4550254e",
   "metadata": {},
   "source": [
    "## Further Experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "10a5b820-ae7a-4366-8098-454bc87ef46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(numb):\n",
    "    x = len(df_p_cut1)\n",
    "    print(\"length of process data before calling data_reducer: \"+str(x))\n",
    "    df_p_cut2 = data_reducer(df_p_cut1,\"UserName\",\"Device\",numb)\n",
    "    y = len(df_p_cut2)\n",
    "    print(\"length of process data after calling data_reducer: \"+str(y))\n",
    "    print(\"Data reduced in size by \"+str(100 - round((y/x)*100,2))+\" %.\")\n",
    "    print(\"\")\n",
    "    x = len(df_a_cut1)\n",
    "    print(\"length of auth data before calling data_reducer: \"+str(x))\n",
    "    df_a_cut2 = data_reducer(df_a_cut1,\"UserName\",\"SrcDevice\",numb)\n",
    "    y = len(df_a_cut2)\n",
    "    print(\"length of auth data after calling data_reducer: \"+str(y))\n",
    "    print(\"Data reduced in size by \"+str(100 - round((y/x)*100,2))+\" %.\")\n",
    "    print(\"\")\n",
    "    print(\"Total process reduction percentage after applying both methods:\")\n",
    "    print(100-round((len(df_p_cut2)/len(df_p))*100,2))\n",
    "    print(\"\")\n",
    "    print(\"Total authentication reduction percentage after applying both methods:\")\n",
    "    print(100-round((y/len(df_a))*100,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "2a1b31c5-daed-4672-8803-8902f17d3d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of process data before calling data_reducer: 53171763\n",
      "length of process data after calling data_reducer: 34800345\n",
      "Data reduced in size by 34.55 %.\n",
      "\n",
      "length of auth data before calling data_reducer: 1219138\n",
      "length of auth data after calling data_reducer: 667614\n",
      "Data reduced in size by 45.24 %.\n",
      "\n",
      "Total process reduction percentage after applying both methods:\n",
      "37.84\n",
      "\n",
      "Total authentication reduction percentage after applying both methods:\n",
      "95.82\n"
     ]
    }
   ],
   "source": [
    "experiment(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "1806c1e7-0dd5-4aa6-8305-c8e508830396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of process data before calling data_reducer: 53171763\n",
      "length of process data after calling data_reducer: 40123718\n",
      "Data reduced in size by 24.540000000000006 %.\n",
      "\n",
      "length of auth data before calling data_reducer: 1219138\n",
      "length of auth data after calling data_reducer: 772570\n",
      "Data reduced in size by 36.63 %.\n",
      "\n",
      "Total process reduction percentage after applying both methods:\n",
      "28.33\n",
      "\n",
      "Total authentication reduction percentage after applying both methods:\n",
      "95.16\n"
     ]
    }
   ],
   "source": [
    "experiment(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "b1f6da0b-79ca-458a-a9f7-7f22a40515ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of process data before calling data_reducer: 53171763\n",
      "length of process data after calling data_reducer: 33504094\n",
      "Data reduced in size by 36.99 %.\n",
      "\n",
      "length of auth data before calling data_reducer: 1219138\n",
      "length of auth data after calling data_reducer: 638470\n",
      "Data reduced in size by 47.63 %.\n",
      "\n",
      "Total process reduction percentage after applying both methods:\n",
      "40.15\n",
      "\n",
      "Total authentication reduction percentage after applying both methods:\n",
      "96.0\n"
     ]
    }
   ],
   "source": [
    "experiment(6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
